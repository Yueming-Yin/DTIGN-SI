{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab320f6-05dd-499f-9acd-15bc708030f7",
   "metadata": {},
   "source": [
    "### Read scores frome csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f60e9-a8c7-45d2-972a-7315b7782f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: I1\n",
      "Fold: 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9ded3d756c4088abd932db2cba1929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.1010, Test Pearson: 0.3124, Test RMSE: 1.5286, Test Kendall Tau: 0.2482\n",
      "Fold: 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bccdb9a6fe4a10b96baed7f3a57c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.1496, Test Pearson: 0.1783, Test RMSE: 1.5076, Test Kendall Tau: 0.2685\n",
      "Fold: 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6400b971f33a4f58be84609f03a9b95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.0490, Test Pearson: 0.1928, Test RMSE: 1.3787, Test Kendall Tau: 0.2491\n",
      "Fold: 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2f10b08a0e49448a065b09161a6a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: -0.0247, Test Pearson: 0.2268, Test RMSE: 1.4275, Test Kendall Tau: 0.2951\n",
      "Fold: 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52198c0179149f98f66c553c5664bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.2811, Test Pearson: 0.3400, Test RMSE: 1.5400, Test Kendall Tau: 0.2757\n",
      "Task: I2\n",
      "Fold: 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a02c2a334d44559e5b7b1257f19c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: -0.5110, Test Pearson: 0.0291, Test RMSE: 1.9731, Test Kendall Tau: -0.0072\n",
      "Fold: 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99193a04cd346a9bc9a057d4341f1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.1588, Test Pearson: 0.1176, Test RMSE: 1.8966, Test Kendall Tau: 0.0489\n",
      "Fold: 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1feeb3a65d483391cdd1569dac9e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.1116, Test Pearson: 0.0016, Test RMSE: 1.9728, Test Kendall Tau: 0.0163\n",
      "Fold: 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14424a99b2e84cf6bbf18ff3a138b31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.1100, Test Pearson: -0.0155, Test RMSE: 1.8373, Test Kendall Tau: -0.0438\n",
      "Fold: 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38793a8cafeb45709f33aaadfec80810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.2682, Test Pearson: -0.0683, Test RMSE: 1.7848, Test Kendall Tau: -0.0381\n",
      "Task: I3\n",
      "Fold: 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8851073961ce4da98935f0343283f56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.0975, Test Pearson: 0.0715, Test RMSE: 2.0716, Test Kendall Tau: 0.0319\n",
      "Fold: 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902959dce8124308b82aa2e4faf7984b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: -0.0035, Test Pearson: 0.0830, Test RMSE: 2.3660, Test Kendall Tau: 0.0455\n",
      "Fold: 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727ecfb3bc1e463bbc5f3de45852ef54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.3850, Test Pearson: 0.0620, Test RMSE: 1.9640, Test Kendall Tau: 0.0270\n",
      "Fold: 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f811f9103d84df5b025ab4a9804ce23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.4534, Test Pearson: 0.0846, Test RMSE: 2.2224, Test Kendall Tau: 0.0485\n",
      "Fold: 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80217e5295b541b29fcf593163188d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.3482, Test Pearson: 0.0804, Test RMSE: 2.1183, Test Kendall Tau: 0.0429\n",
      "Task: I4\n",
      "Fold: 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a456e5a8e7d546dfbda75d6942e761ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.2563, Test Pearson: 0.1137, Test RMSE: 1.3871, Test Kendall Tau: 0.0801\n",
      "Fold: 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e604be336ef4451ebcfb36fbe49daf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: -0.0472, Test Pearson: 0.1111, Test RMSE: 1.4697, Test Kendall Tau: 0.0786\n",
      "Fold: 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85d63df1abb4a2a88968ad931b22513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.1257, Test Pearson: 0.1102, Test RMSE: 1.3972, Test Kendall Tau: 0.0721\n",
      "Fold: 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6fb3317a474c71afb37a01481fe79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: -0.1476, Test Pearson: 0.1159, Test RMSE: 1.3925, Test Kendall Tau: 0.0814\n",
      "Fold: 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8095589ae35d4a099e6661bb3d21f490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.2954, Test Pearson: 0.1200, Test RMSE: 1.3416, Test Kendall Tau: 0.0877\n",
      "Task: I5\n",
      "Fold: 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4137ed9e61ab445e97b71c1bcc8c8744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.2839, Test Pearson: 0.1715, Test RMSE: 1.1695, Test Kendall Tau: 0.0884\n",
      "Fold: 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b11aa43f91444aa7edce0826c82448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping...\n",
      "Best Valid Pearson: 0.3751, Test Pearson: 0.1656, Test RMSE: 1.1671, Test Kendall Tau: 0.0868\n",
      "Fold: 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57367057f5304725b2cadc9591147bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import pearsonr, kendalltau\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "folds = 5\n",
    "data_root = '/home1/yueming/Drug_Discovery/Baselines/GIGN-main/GIGN/data/'\n",
    "result_path = '/home1/yueming/Drug_Discovery/Baselines/GIGN-main/GIGN/results/regression_on_docking_scores.csv'\n",
    "task_dict = {'I1': ('CHEMBL202', 'pIC50', '1boz', 7, 1), 'I2': ('CHEMBL3976', 'pIC50', '4ebb', 2, 4), \n",
    "             'I3': ('CHEMBL333', 'pIC50', '1ck7', 6, 2), 'I4': ('CHEMBL2971', 'pIC50', '3ugc', 3, 4), \n",
    "             'I5': ('CHEMBL279', 'pIC50', '1ywn', 3, 4), 'E1': ('CHEMBL3820', 'pEC50', '3f9m', 6, 3), \n",
    "             'E2': ('CHEMBL4422', 'pEC50', '5tzr', 3, 3), 'E3': ('CHEMBL235', 'pEC50', '1zgy', 4, 2)}\n",
    "set_list = ['test', 'train_1', 'train_2', 'train_3', 'train_4', 'train_5']\n",
    "# Create a dataframe to store test indexes\n",
    "test_results = pd.DataFrame(columns=['Task', 'Fold', 'Val_Pearson', 'Pearson', 'RMSE', 'Kendall Tau'])\n",
    "device = torch.device('cuda:0')\n",
    "hidden_size = 64  # You can adjust this according to your needs\n",
    "output_size = 1   # Since it's regression, output size is 1\n",
    "batch_size = 32  # Adjust batch size according to your needs\n",
    "# Training loop with validation and early stopping\n",
    "num_epochs = 1000\n",
    "patience = 30  # Number of epochs to wait for improvement before early stopping\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define your regression model\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define function to calculate evaluation metrics\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs.float()).squeeze()\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            targets = targets.cpu().numpy()\n",
    "            # Convert scalar output to 1D array\n",
    "            if np.isscalar(outputs):\n",
    "                outputs = np.array([outputs])\n",
    "            if np.isscalar(targets):\n",
    "                targets = np.array([targets])\n",
    "            if isinstance(outputs, np.ndarray) and outputs.ndim == 0:\n",
    "                outputs = np.array([outputs.item()])  # Convert single element array to scalar\n",
    "            if isinstance(targets, np.ndarray) and targets.ndim == 0:\n",
    "                targets = np.array([targets.item()])  # Convert single element array to scalar\n",
    "            preds.extend(outputs.tolist())  # Convert to list before extending\n",
    "            labels.extend(targets.tolist())  # Convert to list before extending\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    pearson_corr, _ = pearsonr(preds, labels)\n",
    "    rmse = np.sqrt(np.mean((preds - labels) ** 2))\n",
    "    kendall_tau, _ = kendalltau(preds, labels)\n",
    "    return pearson_corr, rmse, kendall_tau\n",
    "\n",
    "for task, value in task_dict.items():\n",
    "    # if task != 'I3':\n",
    "    #     continue\n",
    "    print(f\"Task: {task}\")\n",
    "    target, assay, pdb, pockets, poses = value\n",
    "    input_dir = f'{data_root}/{target}/{pdb}/vina/{target}_{assay}'\n",
    "    input_size = pockets * poses # Define your input size based on the number of features\n",
    "\n",
    "    for fold in range(folds):\n",
    "        # if fold != 2:\n",
    "        #     continue\n",
    "        print(f\"Fold: {fold+1}/{folds}\")\n",
    "        \n",
    "        # Initialize your model and optimizer\n",
    "        model = RegressionModel(input_size, hidden_size, output_size).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Loop through input files\n",
    "        train_data, train_label, val_data, val_label, test_data, test_label = [], [], [], [], [], []\n",
    "        for set_name in set_list:\n",
    "            data_path = input_dir + f'_{set_name}.csv'\n",
    "            data_df = pd.read_csv(data_path)\n",
    "            for idx, row in data_df.iterrows():\n",
    "                feature, found_nan = [], False\n",
    "                label = row[assay]\n",
    "                # Get features (docking scores) and labels (bioactivities) for each ligand\n",
    "                for pocket in range(pockets):\n",
    "                    for pose in range(poses):\n",
    "                        column_name = f'Pocket_{pocket+1}_Vina_Score' if task == 'I1' else f'Pocket_{pocket+1}-{pose+1}_Vina_Score'\n",
    "                        score_in_column = row[column_name]\n",
    "                        if np.isnan(score_in_column):\n",
    "                            found_nan = True\n",
    "                        else:\n",
    "                            feature.append(score_in_column)\n",
    "                            \n",
    "                # Discard incomplete docking scores   \n",
    "                if not found_nan:\n",
    "                    if set_name == 'test':\n",
    "                        test_data.append(torch.tensor(feature).unsqueeze(0).to(device))\n",
    "                        test_label.append(torch.tensor(label).long().to(device))\n",
    "                    elif set_name == f'train_{fold+1}':\n",
    "                        val_data.append(torch.tensor(feature).unsqueeze(0).to(device))\n",
    "                        val_label.append(torch.tensor(label).long().to(device))\n",
    "                    else:\n",
    "                        train_data.append(torch.tensor(feature).unsqueeze(0).to(device))\n",
    "                        train_label.append(torch.tensor(label).long().to(device))\n",
    "                        \n",
    "        # Convert data and labels to PyTorch tensors\n",
    "        train_dataset = TensorDataset(torch.stack(train_data), torch.stack(train_label))\n",
    "        val_dataset = TensorDataset(torch.stack(val_data), torch.stack(val_label))\n",
    "        test_dataset = TensorDataset(torch.stack(test_data), torch.stack(test_label))\n",
    "\n",
    "        # Define DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "        best_valid_index = float('-inf')\n",
    "        counter = 0  # Counter for early stopping\n",
    "        # Training loop\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs.float())  # Forward pass\n",
    "                loss = criterion(outputs.squeeze(), labels.float())  # Calculate the loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Optimize\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            \n",
    "            # Validation\n",
    "            val_pearson, val_rmse, val_kendall_tau = evaluate_model(model, val_loader)\n",
    "            # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Pearson: {val_pearson:.4f}, Val RMSE: {val_rmse:.4f}, Val Kendall Tau: {val_kendall_tau:.4f}\")\n",
    "            \n",
    "            # Check for early stopping\n",
    "            if val_pearson > best_valid_index:\n",
    "                best_valid_index = val_pearson\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    print(\"Early stopping...\")\n",
    "                    break\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_pearson, test_rmse, test_kendall_tau = evaluate_model(model, test_loader)\n",
    "        print(f\"Best Valid Pearson: {best_valid_index:.4f}, Test Pearson: {test_pearson:.4f}, Test RMSE: {test_rmse:.4f}, Test Kendall Tau: {test_kendall_tau:.4f}\")\n",
    "\n",
    "        # Append to test results dataframe\n",
    "        result_dict = {\n",
    "            'Task': task,\n",
    "            'Fold': fold + 1,\n",
    "            'Val_Pearson': best_valid_index,\n",
    "            'Pearson': test_pearson,\n",
    "            'RMSE': test_rmse,\n",
    "            'Kendall Tau': test_kendall_tau\n",
    "        }\n",
    "        result_list = []\n",
    "        for key, value in result_dict.items():\n",
    "            result_list.append(value)\n",
    "        test_results.loc[len(test_results.index)] = result_list\n",
    "\n",
    "        # Save the dataframe to result_path at the end of each experiment\n",
    "        test_results.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c48729-1ca2-480e-aea7-78583fa6835a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
